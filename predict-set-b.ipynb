{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea75a64-5136-4132-bc14-6e03c8f57ab4",
   "metadata": {},
   "source": [
    "Import Library/ies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f522f309-75b8-4064-8449-da252a3e77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fd01bf9d-0a81-4b04-862f-8adf3d0647c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_repetition_features(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\"  # Replace non-string or NaN values with an empty string\n",
    "    # Count word repetitions\n",
    "    words = text.split()\n",
    "    word_count = {word: words.count(word) for word in set(words)}\n",
    "    word_repetition = sum(count for count in word_count.values() if count > 1)\n",
    "\n",
    "    # Count letter repetitions\n",
    "    letter_repetition = len(re.findall(r'(.)\\1{2,}', text))  # Counts letters repeated 3 or more times\n",
    "\n",
    "    return pd.Series([word_repetition, letter_repetition])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcfd4af-a6fd-4a22-a9f8-87bf04ab193f",
   "metadata": {},
   "source": [
    "Load the model and vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d3a8bc27-6349-4267-8625-e81265d56302",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('sentiment_model.pkl')\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d87c353-47a0-4798-912a-890089aae591",
   "metadata": {},
   "source": [
    "Load the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "21504fb3-260f-4822-ae6d-d8fd03e86794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('reviews.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcfb6a4-e3ac-4e7f-afa9-73f4d7d81a5e",
   "metadata": {},
   "source": [
    "Convert to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "520fc85c-38d4-4b01-ba53-e002f3476d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "df.to_csv('reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7b404-075c-44a7-8f0e-42390db90a13",
   "metadata": {},
   "source": [
    "Load CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "eb97d2b4-16d1-4fea-a2db-59bee7a46ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'reviews.csv'\n",
    "data = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c0b4fd80-2f56-465c-a0bd-db7777824de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'review' column contains the text\n",
    "X_new = data['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4627b84f-9a61-47d6-b448-5d0142da641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all reviews are strings and handle missing values\n",
    "X_new = data['review'].fillna(\"\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d1d04364-9c22-460f-9a41-c4c48913cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract repetition features\n",
    "repetition_features_new = X_new.apply(calculate_repetition_features)\n",
    "repetition_features_new.columns = ['word_repetition', 'letter_repetition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f0d6f39e-3e08-41dc-a595-871489035a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text using the loaded vectorizer\n",
    "X_tfidf_new = loaded_vectorizer.transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "74f46f45-2b68-4ff9-851a-47f68b5b6a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine TF-IDF with repetition features\n",
    "X_combined_new = sp.hstack([X_tfidf_new, sp.csr_matrix(repetition_features_new.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fbfd8f77-20d5-4405-8edd-2af321284557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiments\n",
    "predictions = loaded_model.predict(X_combined_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "39b29325-cec4-42ef-9567-200315c609ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'predicted_sentiments.csv'\n"
     ]
    }
   ],
   "source": [
    "# Add predictions to the dataset\n",
    "data['predicted_sentiment'] = predictions\n",
    "\n",
    "# Save the results to a CSV\n",
    "data.to_csv('datasetb_withpredictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'predicted_sentiments.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8010b80-426a-4eb0-9749-c00502e9018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.read_json('reviews.json')\n",
    "\n",
    "df.to_csv('new_reviews.csv', index=False)\n",
    "\n",
    "# Load the new dataset\n",
    "new_dataset_path = 'new_reviews.csv'  # Update with your file path\n",
    "new_data = pd.read_csv(new_dataset_path)\n",
    "\n",
    "# Assuming the dataset has a 'review' column\n",
    "reviews = new_data['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f19a657f-b298-4851-83ce-a2aaf49697af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved model and vectorizer\n",
    "loaded_model = joblib.load('improved_logistic_regression_model.pkl')\n",
    "loaded_vectorizer = joblib.load('new_tfidf_vectorizer.pkl')\n",
    "\n",
    "print(\"Model and vectorizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "528eed13-1a2e-4d2c-a456-23a30d6d3ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values in reviews with a placeholder\n",
    "new_data['review'] = new_data['review'].fillna('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6584e2d4-ff2b-4107-90a5-3850be152219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the new reviews\n",
    "reviews_tfidf = loaded_vectorizer.transform(new_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55895eeb-ba7e-4832-b04d-3c47527640b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiments\n",
    "predicted_sentiments = loaded_model.predict(reviews_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69138ff2-2c26-4254-81da-c0e182dd401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to the dataset\n",
    "new_data['predicted_sentiment'] = predicted_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d64f1539-c71a-4349-acd2-cfcb52fa5005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to new_dataset_with_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Map numeric labels to sentiment names\n",
    "sentiment_mapping = {\n",
    "    1: 'Negative',\n",
    "    2: 'Neutral',\n",
    "    3: 'Positive',\n",
    "    4: 'Mixed'\n",
    "}\n",
    "new_data['sentiment_label'] = new_data['predicted_sentiment'].map(sentiment_mapping)\n",
    "\n",
    "# Save the dataset with predictions\n",
    "new_data.to_csv('new_dataset_with_predictions.csv', index=False)\n",
    "print(\"Predictions saved to new_dataset_with_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "410e8aba-9176-496c-ade2-4f3d57d7743d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00       327\n",
      "     Neutral       1.00      1.00      1.00        97\n",
      "    Positive       1.00      1.00      1.00       294\n",
      "       Mixed       1.00      1.00      1.00       283\n",
      "\n",
      "    accuracy                           1.00      1001\n",
      "   macro avg       1.00      1.00      1.00      1001\n",
      "weighted avg       1.00      1.00      1.00      1001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping of string labels to integer labels\n",
    "sentiment_mapping = {\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Positive': 3,\n",
    "    'Mixed': 4\n",
    "}\n",
    "\n",
    "# Apply this mapping to the true sentiment column\n",
    "new_data['sentiment_label'] = new_data['sentiment_label'].map(sentiment_mapping)\n",
    "\n",
    "# Now, the true sentiment labels are integers\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "true_labels = new_data['sentiment_label']\n",
    "predicted_labels = new_data['predicted_sentiment']\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=['Negative', 'Neutral', 'Positive', 'Mixed'])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "172aaf62-2d03-4982-afab-5465ffed1108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[327   0   0   0]\n",
      " [  0  97   0   0]\n",
      " [  0   0 294   0]\n",
      " [  0   0   0 283]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e6f2fb-102c-4079-ad1a-dd74ea83080d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
